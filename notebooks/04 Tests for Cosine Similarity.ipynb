{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests               \n",
    "import pandas as pd          \n",
    "from scrapy import Selector \n",
    "import pprint \n",
    "from tqdm import tqdm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbclink = 'https://www.bbcgoodfood.com/search?q='\n",
    "response = requests.get(bbclink)\n",
    "sel = Selector(text=response.text)\n",
    "links = []\n",
    "\n",
    "recipecards = sel.css('main div.search-results div.card__section.card__content a ::attr(href)').getall()\n",
    "links.extend(recipecards)  \n",
    "prefix = \"https://www.bbcgoodfood.com/recipes/\"\n",
    "final_links = [prefix + item for item in links] \n",
    "print(final_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:33<00:00,  9.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10011"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'https://www.bbcgoodfood.com/search?q=&limit=1000&page='\n",
    "\n",
    "links = []\n",
    "for i in tqdm(range(1, 11)):\n",
    "    response = requests.get(base_url + str(i))\n",
    "    sel = Selector(text = response.text)\n",
    "    recipecards = sel.css('main div.search-results div.card__section.card__content a ::attr(href)').getall()\n",
    "    links.extend(recipecards)  \n",
    "\n",
    "prefix = \"https://www.bbcgoodfood.com/recipes/\"\n",
    "final_links = [prefix + item for item in links] \n",
    "\n",
    "len(final_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame containing the nutritional data of all the recipes on BBCGoodFood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10011/10011 [2:44:43<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>calories</th>\n",
       "      <th>salt</th>\n",
       "      <th>fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicken &amp; chorizo jambalaya</td>\n",
       "      <td>445</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lemon drizzle cake</td>\n",
       "      <td>399</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chilli con carne recipe</td>\n",
       "      <td>387</td>\n",
       "      <td>2.32</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best ever chocolate brownies recipe</td>\n",
       "      <td>150</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creamy courgette lasagne</td>\n",
       "      <td>405</td>\n",
       "      <td>1.36</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name calories  salt fat\n",
       "0          Chicken & chorizo jambalaya      445   1.2  10\n",
       "1                   Lemon drizzle cake      399   0.3  21\n",
       "2              Chilli con carne recipe      387  2.32  17\n",
       "3  Best ever chocolate brownies recipe      150   0.1   9\n",
       "4             Creamy courgette lasagne      405  1.36  21"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = requests.Session()\n",
    "\n",
    "def get_nutrition(url):\n",
    "    response2 = session.get(url)\n",
    "    sel2 = Selector(text=response2.text)\n",
    "    table = sel2.css('table.key-value-blocks.hidden-print.mt-xxs')\n",
    "    bbc = {}\n",
    "    bbc['name'] = sel2.css('h1.heading-1 ::text').get()\n",
    "    bbc['calories'] = table.css('td.key-value-blocks__value ::text').get()\n",
    "    bbc['salt'] = table.xpath('.//*[contains(text(), \"salt\")]/..').css('td.key-value-blocks__value ::text').get()\n",
    "    bbc['fat'] = table.xpath('.//*[contains(text(), \"fat\")]/..').css('td.key-value-blocks__value ::text').get()\n",
    "    return bbc\n",
    "\n",
    "bbc = [get_nutrition(url) for url in tqdm(final_links)]\n",
    "\n",
    "df_bbc = pd.DataFrame(bbc)\n",
    "df_bbc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data as a CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbc.to_csv('../data/bbc_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prawn Katsu Baos</td>\n",
       "      <td>2024-01-17 21:56:28</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "      <td>256</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/1998zka/...</td>\n",
       "      <td>https://i.redd.it/q81uyef4o2dc1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cinnamon Rolls</td>\n",
       "      <td>2024-01-05 17:45:11</td>\n",
       "      <td>251</td>\n",
       "      <td>False</td>\n",
       "      <td>0.96</td>\n",
       "      <td>251</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/18zcqmd/...</td>\n",
       "      <td>https://i.redd.it/7uef78dbsnac1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bacon Jalapeño Sweet Potato Hash</td>\n",
       "      <td>2024-01-03 23:42:20</td>\n",
       "      <td>111</td>\n",
       "      <td>False</td>\n",
       "      <td>0.97</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/18xxyl1/...</td>\n",
       "      <td>https://i.redd.it/jcbdya99abac1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mushroom-Taleggio Risotto</td>\n",
       "      <td>2023-12-31 19:25:22</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>0.98</td>\n",
       "      <td>174</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/18vf164/...</td>\n",
       "      <td>https://i.redd.it/qc5akriilo9c1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cinnamon Oatmeal Chocolate Chip Cookies (Recipe)</td>\n",
       "      <td>2023-12-31 13:19:31</td>\n",
       "      <td>206</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "      <td>206</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/18v7m3w/...</td>\n",
       "      <td>https://i.redd.it/aki9a36yrm9c1.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title          created_utc  ups  \\\n",
       "0                                  Prawn Katsu Baos  2024-01-17 21:56:28  256   \n",
       "1                                    Cinnamon Rolls  2024-01-05 17:45:11  251   \n",
       "2                  Bacon Jalapeño Sweet Potato Hash  2024-01-03 23:42:20  111   \n",
       "3                         Mushroom-Taleggio Risotto  2023-12-31 19:25:22  174   \n",
       "4  Cinnamon Oatmeal Chocolate Chip Cookies (Recipe)  2023-12-31 13:19:31  206   \n",
       "\n",
       "   downs  upvote_ratio  score  num_comments  is_original_content  \\\n",
       "0  False          0.95    256             9                False   \n",
       "1  False          0.96    251            21                False   \n",
       "2  False          0.97    111             9                False   \n",
       "3  False          0.98    174             6                False   \n",
       "4  False          0.95    206            16                False   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  https://reddit.com/r/recipes/comments/1998zka/...   \n",
       "1  https://reddit.com/r/recipes/comments/18zcqmd/...   \n",
       "2  https://reddit.com/r/recipes/comments/18xxyl1/...   \n",
       "3  https://reddit.com/r/recipes/comments/18vf164/...   \n",
       "4  https://reddit.com/r/recipes/comments/18v7m3w/...   \n",
       "\n",
       "                                    url  \n",
       "0  https://i.redd.it/q81uyef4o2dc1.jpeg  \n",
       "1  https://i.redd.it/7uef78dbsnac1.jpeg  \n",
       "2  https://i.redd.it/jcbdya99abac1.jpeg  \n",
       "3  https://i.redd.it/qc5akriilo9c1.jpeg  \n",
       "4  https://i.redd.it/aki9a36yrm9c1.jpeg  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = pd.read_csv('../data/filtered_posts.csv')\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>calories</th>\n",
       "      <th>salt</th>\n",
       "      <th>fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>Cinnamon apple &amp; raisin porridge</td>\n",
       "      <td>206</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>Grilled salmon teriyaki with cucumber salad</td>\n",
       "      <td>340</td>\n",
       "      <td>4.23</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>Persimmon &amp; white chocolate tart with pistachios</td>\n",
       "      <td>934</td>\n",
       "      <td>0.8</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>Christmas ceviche with guacamole</td>\n",
       "      <td>131</td>\n",
       "      <td>1.4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>Thai prawn, squash &amp; pineapple curry</td>\n",
       "      <td>292</td>\n",
       "      <td>2.4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name calories  salt fat\n",
       "10006                  Cinnamon apple & raisin porridge      206   0.1   4\n",
       "10007       Grilled salmon teriyaki with cucumber salad      340  4.23  18\n",
       "10008  Persimmon & white chocolate tart with pistachios      934   0.8  67\n",
       "10009                  Christmas ceviche with guacamole      131   1.4  10\n",
       "10010              Thai prawn, squash & pineapple curry      292   2.4  17"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/v5zskq_n3473s_qmdwjwwd7w0000gn/T/ipykernel_4063/2084550400.py:18: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  if doc_A.similarity(doc_B) > similarity_threshold:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03 Tests for Cosine Similarity.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(df_bbc)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     title_B \u001b[39m=\u001b[39m df_bbc\u001b[39m.\u001b[39miloc[j][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     doc_B \u001b[39m=\u001b[39m nlp(title_B)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mif\u001b[39;00m doc_A\u001b[39m.\u001b[39msimilarity(doc_B) \u001b[39m>\u001b[39m similarity_threshold:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X32sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m merge_columns:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/language.py:1037\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m   1017\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1018\u001b[0m     text: Union[\u001b[39mstr\u001b[39m, Doc],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     component_cfg: Optional[Dict[\u001b[39mstr\u001b[39m, Dict[\u001b[39mstr\u001b[39m, Any]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1022\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Doc:\n\u001b[1;32m   1023\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[39m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[39m    is preserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1037\u001b[0m     doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_doc(text)\n\u001b[1;32m   1038\u001b[0m     \u001b[39mif\u001b[39;00m component_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1039\u001b[0m         component_cfg \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/language.py:1131\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[0;34m(self, doc_like)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1130\u001b[0m     \u001b[39mreturn\u001b[39;00m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(doc_like)\n\u001b[0;32m-> 1131\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE1041\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(doc_like)))\n",
      "\u001b[0;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "similarity_threshold = 0.7\n",
    "\n",
    "df_reddit = df_filtered.copy()\n",
    "\n",
    "# Columns to merge from df_B to df_A when there is a match\n",
    "merge_columns = ['calories', 'salt', 'fat']\n",
    "\n",
    "# Iterate through each pair of titles and merge columns if similarity is above the threshold\n",
    "for i in range(len(df_reddit)):\n",
    "    title_A = df_reddit.iloc[i]['title']\n",
    "    doc_A = nlp(title_A)\n",
    "\n",
    "    for j in range(len(df_bbc)):\n",
    "        title_B = df_bbc.iloc[j]['name']\n",
    "        doc_B = nlp(title_B)\n",
    "\n",
    "        if doc_A.similarity(doc_B) > similarity_threshold:\n",
    "            for col in merge_columns:\n",
    "                df_reddit.at[i, f'{col}_from_bbc'] = df_bbc.iloc[j][col]\n",
    "\n",
    "df_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/v5zskq_n3473s_qmdwjwwd7w0000gn/T/ipykernel_4063/3254384372.py:11: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  df_bbc['similarity'] = df_bbc['name'].apply(lambda name_B: doc_A.similarity(nlp(name_B)))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03 Tests for Cosine Similarity.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     df_bbc\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Apply the custom function to each row in df_reddit\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m df_reddit\u001b[39m.\u001b[39mapply(get_similarity, df_bbc\u001b[39m=\u001b[39mdf_bbc, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m df_reddit\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10022\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10024\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m  10025\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  10026\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10032\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m  10033\u001b[0m )\n\u001b[0;32m> 10034\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    835\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 837\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 963\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_series_generator()\n\u001b[1;32m    965\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:979\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    977\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    978\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(v, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[1;32m    980\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    981\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    982\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    983\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03 Tests for Cosine Similarity.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m doc_A \u001b[39m=\u001b[39m nlp(title_A)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Apply the similarity calculation to the entire 'title' column in df_bbc\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df_bbc[\u001b[39m'\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_bbc[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m name_B: doc_A\u001b[39m.\u001b[39msimilarity(nlp(name_B)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Filter rows in df_bbc based on the threshold\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m matches \u001b[39m=\u001b[39m df_bbc[df_bbc[\u001b[39m'\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m similarity_threshold]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4751\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4753\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4754\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   4755\u001b[0m         func,\n\u001b[1;32m   4756\u001b[0m         convert_dtype\u001b[39m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4757\u001b[0m         by_row\u001b[39m=\u001b[39mby_row,\n\u001b[1;32m   4758\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m   4759\u001b[0m         kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m-> 4760\u001b[0m     )\u001b[39m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1206\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_map_values(\n\u001b[1;32m   1288\u001b[0m     mapper\u001b[39m=\u001b[39mcurried, na_action\u001b[39m=\u001b[39maction, convert\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dtype\n\u001b[1;32m   1289\u001b[0m )\n\u001b[1;32m   1291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39mna_action, convert\u001b[39m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(values, mapper, convert\u001b[39m=\u001b[39mconvert)\n\u001b[1;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03 Tests for Cosine Similarity.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m doc_A \u001b[39m=\u001b[39m nlp(title_A)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Apply the similarity calculation to the entire 'title' column in df_bbc\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df_bbc[\u001b[39m'\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_bbc[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m name_B: doc_A\u001b[39m.\u001b[39msimilarity(nlp(name_B)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Filter rows in df_bbc based on the threshold\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m matches \u001b[39m=\u001b[39m df_bbc[df_bbc[\u001b[39m'\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m similarity_threshold]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/language.py:1037\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m   1017\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1018\u001b[0m     text: Union[\u001b[39mstr\u001b[39m, Doc],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     component_cfg: Optional[Dict[\u001b[39mstr\u001b[39m, Dict[\u001b[39mstr\u001b[39m, Any]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1022\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Doc:\n\u001b[1;32m   1023\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[39m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[39m    is preserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1037\u001b[0m     doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_doc(text)\n\u001b[1;32m   1038\u001b[0m     \u001b[39mif\u001b[39;00m component_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1039\u001b[0m         component_cfg \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/language.py:1131\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[0;34m(self, doc_like)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1130\u001b[0m     \u001b[39mreturn\u001b[39;00m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(doc_like)\n\u001b[0;32m-> 1131\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE1041\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(doc_like)))\n",
      "\u001b[0;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "similarity_threshold = 0.7\n",
    "\n",
    "df_reddit = df_filtered.copy()\n",
    "\n",
    "def get_similarity(row_A, df_bbc):\n",
    "    title_A = row_A['title']\n",
    "    doc_A = nlp(title_A)\n",
    "    \n",
    "    # Apply the similarity calculation to the entire 'title' column in df_bbc\n",
    "    df_bbc['similarity'] = df_bbc['name'].apply(lambda name_B: doc_A.similarity(nlp(name_B)))\n",
    "    # Filter rows in df_bbc based on the threshold\n",
    "    matches = df_bbc[df_bbc['similarity'] > similarity_threshold]\n",
    "    \n",
    "    # Merge columns from df_bbc to df_reddit if there are matches\n",
    "    if not matches.empty:\n",
    "        matched_columns = ['calories', 'salt', 'fat']\n",
    "        for col in matched_columns:\n",
    "            df_reddit[col + '_from_bbc'] = matches[col].values\n",
    "    \n",
    "    # Drop the temporary 'similarity' column from df_bbc\n",
    "    df_bbc.drop(columns=['similarity'], inplace=True)\n",
    "\n",
    "# Apply the custom function to each row in df_reddit\n",
    "df_reddit.apply(get_similarity, df_bbc=df_bbc, axis=1)\n",
    "\n",
    "df_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03 Tests for Cosine Similarity.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Iterate through each row in df_reddit and calculate similarities with df_bbc\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, row_reddit \u001b[39min\u001b[39;00m df_reddit\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     similarities \u001b[39m=\u001b[39m calculate_similarity(row_reddit, df_bbc)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# Check if any similarity is above the threshold\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(similarity \u001b[39m>\u001b[39m similarity_threshold \u001b[39mfor\u001b[39;00m similarity \u001b[39min\u001b[39;00m similarities):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         \u001b[39m# Find the index with the maximum similarity\u001b[39;00m\n",
      "\u001b[1;32m/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03 Tests for Cosine Similarity.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m title_bbc \u001b[39m=\u001b[39m row_bbc[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Check if the embedding is not None before attempting to reshape\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m embedding_bbc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencode([title_bbc])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m embedding_bbc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(embedding_bbc) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Yuyao/Desktop/DS105/ds105a-project-chadgpt/notebooks/03%20Tests%20for%20Cosine%20Similarity.ipynb#X33sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     embedding_bbc \u001b[39m=\u001b[39m embedding_bbc[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:161\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m start_index \u001b[39min\u001b[39;00m trange(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(sentences), batch_size, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatches\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    160\u001b[0m     sentences_batch \u001b[39m=\u001b[39m sentences_sorted[start_index:start_index\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m--> 161\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenize(sentences_batch)\n\u001b[1;32m    162\u001b[0m     features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:319\u001b[0m, in \u001b[0;36mSentenceTransformer.tokenize\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(\u001b[39mself\u001b[39m, texts: Union[List[\u001b[39mstr\u001b[39m], List[Dict], List[Tuple[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]]):\n\u001b[1;32m    316\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39m    Tokenizes the texts\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_module()\u001b[39m.\u001b[39mtokenize(texts)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:102\u001b[0m, in \u001b[0;36mTransformer.tokenize\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    100\u001b[0m batch1, batch2 \u001b[39m=\u001b[39m [], []\n\u001b[1;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m text_tuple \u001b[39min\u001b[39;00m texts:\n\u001b[0;32m--> 102\u001b[0m     batch1\u001b[39m.\u001b[39mappend(text_tuple[\u001b[39m0\u001b[39m])\n\u001b[1;32m    103\u001b[0m     batch2\u001b[39m.\u001b[39mappend(text_tuple[\u001b[39m1\u001b[39m])\n\u001b[1;32m    104\u001b[0m to_tokenize \u001b[39m=\u001b[39m [batch1, batch2]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "df_reddit = df_filtered.copy()\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "similarity_threshold = 0.7\n",
    "\n",
    "# Function to calculate cosine similarity between titles\n",
    "def calculate_similarity(row_reddit, df_bbc):\n",
    "    title_reddit = row_reddit['title']\n",
    "    embedding_reddit = model.encode([title_reddit])[0].reshape(1, -1)\n",
    "\n",
    "    similarities = []\n",
    "    for _, row_bbc in df_bbc.iterrows():\n",
    "        title_bbc = row_bbc['name']\n",
    "        \n",
    "        # Check if the embedding is not None before attempting to reshape\n",
    "        embedding_bbc = model.encode([title_bbc])\n",
    "        if embedding_bbc is not None and len(embedding_bbc) > 0:\n",
    "            embedding_bbc = embedding_bbc[0].reshape(1, -1)\n",
    "        else:\n",
    "            # Handle the case where the embedding is None or empty\n",
    "            continue\n",
    "\n",
    "        similarity_score = cosine_similarity(embedding_reddit, embedding_bbc)[0][0]\n",
    "        similarities.append(similarity_score)\n",
    "\n",
    "    return similarities\n",
    "\n",
    "# Columns to merge from df_bbc to df_reddit when there is a match\n",
    "merge_columns = ['calories', 'salt', 'fat']\n",
    "\n",
    "# Iterate through each row in df_reddit and calculate similarities with df_bbc\n",
    "for i, row_reddit in df_reddit.iterrows():\n",
    "    similarities = calculate_similarity(row_reddit, df_bbc)\n",
    "\n",
    "    # Check if any similarity is above the threshold\n",
    "    if any(similarity > similarity_threshold for similarity in similarities):\n",
    "        # Find the index with the maximum similarity\n",
    "        max_index = similarities.index(max(similarities))\n",
    "\n",
    "        # Merge columns from df_bbc to df_reddit using values from the most similar title\n",
    "        for col in merge_columns:\n",
    "            df_reddit.at[i, f'{col}_from_df_bbc'] = df_bbc.iloc[max_index][col]\n",
    "\n",
    "df_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02184611  0.00591048  0.00187744 ... -0.00569096 -0.02545492\n",
      "  -0.01958655]\n",
      " [-0.01549129  0.00366342  0.00322168 ...  0.0223089  -0.02564218\n",
      "  -0.01029447]]\n"
     ]
    }
   ],
   "source": [
    "title1 = \"Creamy Lemon-Basil Chicken Pasta\"\n",
    "title2 = \"Chicken & bacon pasta\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [title1, title2]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.6690070629119873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "embedding1 = embeddings[0].reshape(1, -1)\n",
    "embedding2 = embeddings[1].reshape(1, -1)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_score = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "print(f\"Cosine Similarity: {similarity_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
