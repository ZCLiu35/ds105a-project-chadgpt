{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚úÖStep 1: Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. üéØImport libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import requests as r\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from scrapy import Selector\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import spacy\n",
    "# import plotnine\n",
    "# import altair\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our own modules\n",
    "sys.path.append(\"../scripts/\")\n",
    "import chadtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üéØAuthenticate with Reddit API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a function defined in our `utils.py` script, we can authenticate with the Reddit API using our own `credentials.json` file, and get a `dict` of headers to be used in all subsequent GET requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNzAyMDc4ODU2LjY4ODgyMiwiaWF0IjoxNzAxOTkyNDU2LjY4ODgyMiwianRpIjoibkZLVFdvbXdQWkF5YS1rMzNkX0toa0RFOTVuMWZRIiwiY2lkIjoiVFJicTdUNUZLby1kTU1iSk5vMTdEQSIsImxpZCI6InQyXzJpOWF4eDh3IiwiYWlkIjoidDJfMmk5YXh4OHciLCJsY2EiOjE1NDA4OTAxODI0NTUsInNjcCI6ImVKeUtWdEpTaWdVRUFBRF9fd056QVNjIiwiZmxvIjo5fQ.ku9PZFhOac14VptdffbNP8aVU5lEjpHF_XLmLUsPwuNzC60HXdStNe7A8aZP_cicY5BOfdq2GplK9G_IxRLwzsnOeYNMnL1evY7Ot3UWIVxF0Pg5VOdGve89ee2hsZQ38NLUfxUwV2PY5pxv7-yOISWOo2NC6qSA_LB9wzuI40_aoMtCpVRllgUCoz-LDDjOLxh-FtJOcdOFd_e4lNTgkM35s3P72iXm7JiQuSmpHidOK2FwPaYPoVSpYUr6EveGV9Bv4HpdQPJmJQ_YAGuGd4VJhGwoRjE_uufXIxdeIm9FXbxfPONrsJtNic4wArCT3uhnVoANZ7onSb4CffHjCQ',\n",
       " 'User-Agent': 'LSE DS105A Recipe Scraping Project by rainshake'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = chadtools.authenticate_and_get_headers()\n",
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üéØSending our GET requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prepare GET request for all Flairs + Paginate through all search results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to loop through each flair using For Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `after` ID given by the reddit API to paginate through until the last post matching the search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2067\n"
     ]
    }
   ],
   "source": [
    "s = r.Session()\n",
    "BASE_ENDPOINT = \"https://oauth.reddit.com\"\n",
    "flair_names = ['Recipe', 'Dessert', 'Pasta', 'Poultry', 'Vegetarian', 'Drink', 'Beef', 'Pork', 'Seafood', 'Fruit\\Vegetarian']\n",
    "subreddit_name = 'recipes'\n",
    "\n",
    "\n",
    "all_data_for_all_flairs = []\n",
    "all_data_by_flair = {}\n",
    "\n",
    "\n",
    "for flair in flair_names:\n",
    "    flair_query = f'flair_name:\"{flair}\"'\n",
    "    specific_date_time = datetime(2020, 8, 31, 10, 59, 0)\n",
    "    timestamp = int(specific_date_time.timestamp())\n",
    "    params = {\n",
    "        'q': flair_query,\n",
    "        'limit': 100,\n",
    "        'restrict_sr': 1,\n",
    "        'sort': 'new',\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "    response = s.get(f\"{BASE_ENDPOINT}/r/{subreddit_name}/search\", params=params, headers=headers)\n",
    "    # Initialize an empty list to store the data from page for the current flair\n",
    "    all_data_by_flair[flair] = []\n",
    "    \n",
    "\n",
    "    # Process the data from the first page\n",
    "    data = response.json()\n",
    "    all_data_by_flair[flair].extend(data['data']['children'])\n",
    "\n",
    "    # Page 02 and beyond\n",
    "    while 'after' in data['data'] and data['data']['after'] is not None:\n",
    "        after_id = data['data']['after']\n",
    "        params[\"after\"] = after_id\n",
    "        response = s.get(f\"{BASE_ENDPOINT}/r/{subreddit_name}/search\", params=params, headers=headers)\n",
    "        # print(f\"Requesting Page {len(all_data_by_flair[flair]) // params['limit'] + 1}\")\n",
    "        data = response.json()\n",
    "\n",
    "        # Process the data from the current page\n",
    "        #all_data_by_flair.extend(data['data']['children'])\n",
    "        all_data_by_flair[flair].extend(data['data']['children'])\n",
    "    \n",
    "    all_data_for_all_flairs.extend(all_data_by_flair[flair])\n",
    "    \n",
    "pprint(len(all_data_for_all_flairs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üéØSaving the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Save the data as a JSON file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/all_data_for_all_flairs.json\", \"w\") as f:\n",
    "    json.dump( all_data_for_all_flairs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load the JSON file as a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/all_data_for_all_flairs.json\", \"r\") as file:\n",
    "    posts = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create a dataframe of all posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classic Tiramisu Recipe (original Italian pizz...</td>\n",
       "      <td>1.701864e+09</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/recipes/comments/18c2c0q/classic_tiramisu_r...</td>\n",
       "      <td>https://www.diyfoodhacks.com/classic-tiramisu-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orange Cookies üçäüß°</td>\n",
       "      <td>1.701750e+09</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>175</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/recipes/comments/18b3ir1/orange_cookies/</td>\n",
       "      <td>https://i.redd.it/37t5h7ssje4c1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stir Fry Supreme ‚Äì Chives, cashews and Shrimp</td>\n",
       "      <td>1.701695e+09</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/recipes/comments/18ajm70/stir_fry_supreme_c...</td>\n",
       "      <td>https://i.redd.it/6vrftswiz94c1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sous Vide Chicken and Potatoes</td>\n",
       "      <td>1.701651e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/recipes/comments/18a88g3/sous_vide_chicken_...</td>\n",
       "      <td>https://i.redd.it/rcgqae55e64c1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicken Riggies</td>\n",
       "      <td>1.701551e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/recipes/comments/189d72m/chicken_riggies/</td>\n",
       "      <td>https://i.redd.it/bn11tg3i5y3c1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   created_utc  ups  \\\n",
       "0  Classic Tiramisu Recipe (original Italian pizz...  1.701864e+09   19   \n",
       "1                                  Orange Cookies üçäüß°  1.701750e+09  175   \n",
       "2      Stir Fry Supreme ‚Äì Chives, cashews and Shrimp  1.701695e+09  100   \n",
       "3                     Sous Vide Chicken and Potatoes  1.701651e+09    9   \n",
       "4                                    Chicken Riggies  1.701551e+09    1   \n",
       "\n",
       "   downs  upvote_ratio  score  num_comments  is_original_content  \\\n",
       "0      0          0.80     19             5                False   \n",
       "1      0          0.97    175             6                False   \n",
       "2      0          0.91    100             9                False   \n",
       "3      0          1.00      9             1                False   \n",
       "4      0          1.00      1             1                False   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/recipes/comments/18c2c0q/classic_tiramisu_r...   \n",
       "1        /r/recipes/comments/18b3ir1/orange_cookies/   \n",
       "2  /r/recipes/comments/18ajm70/stir_fry_supreme_c...   \n",
       "3  /r/recipes/comments/18a88g3/sous_vide_chicken_...   \n",
       "4       /r/recipes/comments/189d72m/chicken_riggies/   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.diyfoodhacks.com/classic-tiramisu-...  \n",
       "1                https://i.redd.it/37t5h7ssje4c1.jpg  \n",
       "2               https://i.redd.it/6vrftswiz94c1.jpeg  \n",
       "3                https://i.redd.it/rcgqae55e64c1.jpg  \n",
       "4                https://i.redd.it/bn11tg3i5y3c1.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts = pd.json_normalize(posts, max_level=0)\n",
    "df_posts = pd.json_normalize(df_posts['data'])\n",
    "selected_cols = ['title', 'created_utc', 'ups', 'downs', 'upvote_ratio', 'score', 'num_comments', 'is_original_content', 'permalink', 'url']\n",
    "\n",
    "df_posts = df_posts[selected_cols].copy()\n",
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classic Tiramisu Recipe (original Italian pizz...</td>\n",
       "      <td>1.701864e+09</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/18c2c0q/...</td>\n",
       "      <td>https://www.diyfoodhacks.com/classic-tiramisu-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orange Cookies üçäüß°</td>\n",
       "      <td>1.701750e+09</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>175</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/18b3ir1/...</td>\n",
       "      <td>https://i.redd.it/37t5h7ssje4c1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stir Fry Supreme ‚Äì Chives, cashews and Shrimp</td>\n",
       "      <td>1.701695e+09</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/18ajm70/...</td>\n",
       "      <td>https://i.redd.it/6vrftswiz94c1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sous Vide Chicken and Potatoes</td>\n",
       "      <td>1.701651e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/18a88g3/...</td>\n",
       "      <td>https://i.redd.it/rcgqae55e64c1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicken Riggies</td>\n",
       "      <td>1.701551e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/189d72m/...</td>\n",
       "      <td>https://i.redd.it/bn11tg3i5y3c1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   created_utc  ups  \\\n",
       "0  Classic Tiramisu Recipe (original Italian pizz...  1.701864e+09   19   \n",
       "1                                  Orange Cookies üçäüß°  1.701750e+09  175   \n",
       "2      Stir Fry Supreme ‚Äì Chives, cashews and Shrimp  1.701695e+09  100   \n",
       "3                     Sous Vide Chicken and Potatoes  1.701651e+09    9   \n",
       "4                                    Chicken Riggies  1.701551e+09    1   \n",
       "\n",
       "   downs  upvote_ratio  score  num_comments  is_original_content  \\\n",
       "0      0          0.80     19             5                False   \n",
       "1      0          0.97    175             6                False   \n",
       "2      0          0.91    100             9                False   \n",
       "3      0          1.00      9             1                False   \n",
       "4      0          1.00      1             1                False   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  https://reddit.com/r/recipes/comments/18c2c0q/...   \n",
       "1  https://reddit.com/r/recipes/comments/18b3ir1/...   \n",
       "2  https://reddit.com/r/recipes/comments/18ajm70/...   \n",
       "3  https://reddit.com/r/recipes/comments/18a88g3/...   \n",
       "4  https://reddit.com/r/recipes/comments/189d72m/...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.diyfoodhacks.com/classic-tiramisu-...  \n",
       "1                https://i.redd.it/37t5h7ssje4c1.jpg  \n",
       "2               https://i.redd.it/6vrftswiz94c1.jpeg  \n",
       "3                https://i.redd.it/rcgqae55e64c1.jpg  \n",
       "4                https://i.redd.it/bn11tg3i5y3c1.jpg  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize JSON data in 'posts' and create a DataFrame\n",
    "df_posts = pd.json_normalize(posts, max_level=0)\n",
    "\n",
    "# handle NaN values in the 'data' column by replacing them with an empty dictionary\n",
    "df_posts['data'] = df_posts['data'].apply(lambda x: {} if pd.isna(x) else x)    \n",
    "\n",
    "# concatenate the original DataFrame with a new DataFrame created from normalizing the 'data' column\n",
    "df_posts = pd.concat([df_posts.drop(['data'], axis=1), pd.json_normalize(df_posts['data'])], axis=1)\n",
    "\n",
    "# select specific columns from the dataframe\n",
    "selected_cols = ['title', 'created_utc', 'ups', 'downs', 'upvote_ratio', 'score', 'num_comments', 'is_original_content', 'permalink', 'url']\n",
    "df_posts = df_posts[selected_cols].copy()\n",
    "\n",
    "# add a prefix to the 'permalink' column\n",
    "df_posts['permalink'] = \"https://reddit.com\" + df_posts['permalink']   \n",
    "\n",
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-English posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the data easier to analyse using NLP techniques, we will filter out posts that are not in English."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FAILED method\n",
    "# Function to check if text is in English\n",
    "def is_english(text):\n",
    "    language, confidence = langid.classify(text)\n",
    "    return language == 'en' and confidence > 0.00000000001  # Adjust confidence threshold as needed\n",
    "\n",
    "# Apply the function to filter rows\n",
    "filtered_df = df_posts[df_posts['title'].apply(is_english)]\n",
    "\n",
    "print(filtered_df)\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>Bhindi</td>\n",
       "      <td>1.567057e+09</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/cwwkcq/b...</td>\n",
       "      <td>https://i.redd.it/y6698lnkqbj31.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>Restaurant Style Phool Gobhi Masala Recipe</td>\n",
       "      <td>1.567056e+09</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/cwwfal/r...</td>\n",
       "      <td>https://i.redd.it/ycwjgo0pnbj31.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>Celery and Soy Stuffed Butternut Squash</td>\n",
       "      <td>1.566290e+09</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/csv234/c...</td>\n",
       "      <td>https://imgur.com/OyakVfz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>Grilled Nectarine Caprese Salad</td>\n",
       "      <td>1.566144e+09</td>\n",
       "      <td>1723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1723</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/cs2z3v/g...</td>\n",
       "      <td>https://i.redd.it/tzjwjnulc8h31.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>The right way to cut watermelon</td>\n",
       "      <td>1.565469e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>https://reddit.com/r/recipes/comments/con4hp/t...</td>\n",
       "      <td>https://i.redd.it/w72ozivbkof31.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title   created_utc   ups  downs  \\\n",
       "2062                                      Bhindi  1.567057e+09    15      0   \n",
       "2063  Restaurant Style Phool Gobhi Masala Recipe  1.567056e+09    21      0   \n",
       "2064     Celery and Soy Stuffed Butternut Squash  1.566290e+09     7      0   \n",
       "2065             Grilled Nectarine Caprese Salad  1.566144e+09  1723      0   \n",
       "2066             The right way to cut watermelon  1.565469e+09     0      0   \n",
       "\n",
       "      upvote_ratio  score  num_comments  is_original_content  \\\n",
       "2062          0.75     15             3                False   \n",
       "2063          0.88     21             1                False   \n",
       "2064          0.74      7             1                False   \n",
       "2065          0.97   1723            22                False   \n",
       "2066          0.36      0             8                False   \n",
       "\n",
       "                                              permalink  \\\n",
       "2062  https://reddit.com/r/recipes/comments/cwwkcq/b...   \n",
       "2063  https://reddit.com/r/recipes/comments/cwwfal/r...   \n",
       "2064  https://reddit.com/r/recipes/comments/csv234/c...   \n",
       "2065  https://reddit.com/r/recipes/comments/cs2z3v/g...   \n",
       "2066  https://reddit.com/r/recipes/comments/con4hp/t...   \n",
       "\n",
       "                                      url  \n",
       "2062  https://i.redd.it/y6698lnkqbj31.jpg  \n",
       "2063  https://i.redd.it/ycwjgo0pnbj31.jpg  \n",
       "2064            https://imgur.com/OyakVfz  \n",
       "2065  https://i.redd.it/tzjwjnulc8h31.jpg  \n",
       "2066  https://i.redd.it/w72ozivbkof31.jpg  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the English language model into spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# filter the english posts by applying custom function\n",
    "filtered_df_posts = df_posts[df_posts['title'].apply(chadtools.is_english, model=nlp)]\n",
    "filtered_df_posts.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Save dataframe as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_posts.to_csv('../data/posts.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Specify the subreddit and flair\\nsubreddit_name = \\'recipes\\'\\nflair_name = \\'recipe\\'  # Change this to the desired flair\\n\\n# Reddit API endpoint for searching posts in a subreddit\\nurl = f\\'https://www.reddit.com/r/{subreddit_name}/search.json\\'\\n\\n# Define parameters for the search query\\nparams = {\\n    \\'q\\': f\\'flair_name:\"{flair_name}\"\\',\\n    \\'restrict_sr\\': \\'on\\',  # Restrict the search to the specified subreddit\\n    \\'sort\\': \\'new\\',       # Sort by new to get all posts\\n    \\'syntax\\': \\'cloudsearch\\'\\n}\\n\\n# Make the API request\\nresponse = s.get(url, params=params, headers={\\'User-agent\\': \\'your_user_agent\\'})\\n\\n# Check if the request was successful (status code 200)\\nif response.status_code == 200:\\n    # Parse the JSON response\\n    data = response.json()\\n    \\n    # Get the number of posts\\n    num_posts = data[\\'data\\'][\\'dist\\']\\n    \\n    print(f\"Number of posts with \\'{flair_name}\\' flair in r/{subreddit_name}: {num_posts}\")\\nelse:\\n    print(f\"Error: {response.status_code}\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Specify the subreddit and flair\n",
    "subreddit_name = 'recipes'\n",
    "flair_name = 'recipe'  # Change this to the desired flair\n",
    "\n",
    "# Reddit API endpoint for searching posts in a subreddit\n",
    "url = f'https://www.reddit.com/r/{subreddit_name}/search.json'\n",
    "\n",
    "# Define parameters for the search query\n",
    "params = {\n",
    "    'q': f'flair_name:\"{flair_name}\"',\n",
    "    'restrict_sr': 'on',  # Restrict the search to the specified subreddit\n",
    "    'sort': 'new',       # Sort by new to get all posts\n",
    "    'syntax': 'cloudsearch'\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = s.get(url, params=params, headers={'User-agent': 'your_user_agent'})\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    \n",
    "    # Get the number of posts\n",
    "    num_posts = data['data']['dist']\n",
    "    \n",
    "    print(f\"Number of posts with '{flair_name}' flair in r/{subreddit_name}: {num_posts}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds105",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
