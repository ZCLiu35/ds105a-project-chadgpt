{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âœ…Step 1: Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ðŸŽ¯Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Import our own modules\u001b[39;00m\n\u001b[0;32m     10\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../scripts/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchadtools\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zicheng Liu\\prog\\LSE\\DS105\\Final Project\\ds105a-project-chadgpt\\notebooks\\../scripts\\chadtools.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mr\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlangid\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# AUTHENTICATE WITH CREDENTIALS TO GET ACCESS TOKEN AND HEADERS\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import requests as r\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our own modules\n",
    "sys.path.append(\"../scripts/\")\n",
    "import chadtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ðŸŽ¯Authenticate with Reddit API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a function defined in our `utils.py` script, we can authenticate with the Reddit API using our own `credentials.json` file, and get a `dict` of headers to be used in all subsequent GET requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNzA3MTc2ODM4Ljk5NzM2MywiaWF0IjoxNzA3MDkwNDM4Ljk5NzM2MywianRpIjoiNVhoVHRyNVdZRi1tTFZkSzIwNXNlOXlnc2VyMVFnIiwiY2lkIjoibWhUbV82eEVUNzVkOWhmWkJrS0ZYQSIsImxpZCI6InQyXzE2ZmE0MiIsImFpZCI6InQyXzE2ZmE0MiIsImxjYSI6MTQ5MDI0NzcyNzAxMSwic2NwIjoiZUp5S1Z0SlNpZ1VFQUFEX193TnpBU2MiLCJmbG8iOjl9.N0ofvuhtISp6I8qnZQwdfq5QaT-txlOGrPzb0VtSUpTBZL8cR6gXgtuPKKMUJ3n9q9HjhthM5WKWaBGJQL_c_Hj1pzD0r3nXWJfJ9f9H5DwP-bkM55R_CD0A5mfN2dfnjI4GD20fXEXNK-XTvn5Luv9ZrLPV_klOzA2ZNXWq2BWhLLI9juIEFoNaA0-rllu5MiITZqn72Zk8aygTifG0Fvujk-aK34rdpq-ezhSH0Co1Nn4M8y01MpmO3eSC61OhY1g6fsaKgOKKWgJ9UvXCyLA9frNcQz8-cN0-DGbxGa26fjcjgAWLTLS0nn5l6Cs3Jrdl3d9UE2oLYOs4PVcXtA',\n",
       " 'User-Agent': 'LSE DS105A Recipe Scraping Project by zichengliu'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = chadtools.authenticate_and_get_headers()\n",
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ðŸŽ¯Sending our GET requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prepare GET request for all Flairs + Paginate through all search results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get all the posts from the subreddit, we will iterate through a list of all the flairs in the subreddit and send a GET request for each flair. We will then paginate through the search results using the `after` ID given by Reddit's API to get all the posts for each flair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2066"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = r.Session()\n",
    "BASE_ENDPOINT = \"https://oauth.reddit.com\"\n",
    "flair_names = ['Recipe', 'Dessert', 'Pasta', 'Poultry', 'Vegetarian', 'Drink', 'Beef', 'Pork', 'Seafood', 'Fruit\\Vegetarian']\n",
    "subreddit_name = 'recipes'\n",
    "\n",
    "all_data_for_all_flairs = []\n",
    "all_data_by_flair = {}\n",
    "\n",
    "for flair in tqdm(flair_names):\n",
    "    flair_query = f'flair_name:\"{flair}\"'\n",
    "    params = {\n",
    "        'q': flair_query,\n",
    "        'limit': 100,\n",
    "        'restrict_sr': 1,\n",
    "        'sort': 'new'\n",
    "    }\n",
    "    response = s.get(f\"{BASE_ENDPOINT}/r/{subreddit_name}/search\", params=params, headers=headers)\n",
    "    # Initialize an empty list to store the data from page for the current flair\n",
    "    all_data_by_flair[flair] = []\n",
    "    \n",
    "    # Process the data from the first page\n",
    "    data = response.json()\n",
    "    all_data_by_flair[flair].extend(data['data']['children'])\n",
    "\n",
    "    # Page 02 and beyond\n",
    "    while 'after' in data['data'] and data['data']['after'] is not None:\n",
    "        after_id = data['data']['after']\n",
    "        params[\"after\"] = after_id\n",
    "        response = s.get(f\"{BASE_ENDPOINT}/r/{subreddit_name}/search\", params=params, headers=headers)\n",
    "        # print(f\"Requesting Page {len(all_data_by_flair[flair]) // params['limit'] + 1}\")\n",
    "        data = response.json()\n",
    "\n",
    "        # Process the data from the current page\n",
    "        #all_data_by_flair.extend(data['data']['children'])\n",
    "        all_data_by_flair[flair].extend(data['data']['children'])\n",
    "    \n",
    "    all_data_for_all_flairs.extend(all_data_by_flair[flair])\n",
    "    \n",
    "len(all_data_for_all_flairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ðŸŽ¯Saving the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create a dataframe of all posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>is_gallery</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>gallery_data</th>\n",
       "      <th>poll_data</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>crosspost_parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>None</td>\n",
       "      <td>recipes</td>\n",
       "      <td></td>\n",
       "      <td>t2_71qg7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Eggplant Chickpea Dip</td>\n",
       "      <td>[{'e': 'text', 't': 'Fruit\\Vegetarian'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>None</td>\n",
       "      <td>recipes</td>\n",
       "      <td></td>\n",
       "      <td>t2_3hz99hdf</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>End-Of-Summer Sesame Slaw</td>\n",
       "      <td>[{'e': 'text', 't': 'Fruit\\Vegetarian'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>None</td>\n",
       "      <td>recipes</td>\n",
       "      <td></td>\n",
       "      <td>t2_3ftl8yf0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Bhindi</td>\n",
       "      <td>[{'e': 'text', 't': 'Fruit\\Vegetarian'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>None</td>\n",
       "      <td>recipes</td>\n",
       "      <td></td>\n",
       "      <td>t2_3ftl8yf0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Restaurant Style Phool Gobhi Masala Recipe</td>\n",
       "      <td>[{'e': 'text', 't': 'Fruit\\Vegetarian'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>None</td>\n",
       "      <td>recipes</td>\n",
       "      <td></td>\n",
       "      <td>t2_71qg7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Celery and Soy Stuffed Butternut Squash</td>\n",
       "      <td>[{'e': 'text', 't': 'Fruit\\Vegetarian'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     approved_at_utc subreddit selftext author_fullname  saved  \\\n",
       "2061            None   recipes                 t2_71qg7  False   \n",
       "2062            None   recipes              t2_3hz99hdf  False   \n",
       "2063            None   recipes              t2_3ftl8yf0  False   \n",
       "2064            None   recipes              t2_3ftl8yf0  False   \n",
       "2065            None   recipes                 t2_71qg7  False   \n",
       "\n",
       "     mod_reason_title  gilded  clicked  \\\n",
       "2061             None       0    False   \n",
       "2062             None       0    False   \n",
       "2063             None       0    False   \n",
       "2064             None       0    False   \n",
       "2065             None       0    False   \n",
       "\n",
       "                                           title  \\\n",
       "2061                       Eggplant Chickpea Dip   \n",
       "2062                   End-Of-Summer Sesame Slaw   \n",
       "2063                                      Bhindi   \n",
       "2064  Restaurant Style Phool Gobhi Masala Recipe   \n",
       "2065     Celery and Soy Stuffed Butternut Squash   \n",
       "\n",
       "                           link_flair_richtext  ... num_crossposts  media  \\\n",
       "2061  [{'e': 'text', 't': 'Fruit\\Vegetarian'}]  ...              0   None   \n",
       "2062  [{'e': 'text', 't': 'Fruit\\Vegetarian'}]  ...              0   None   \n",
       "2063  [{'e': 'text', 't': 'Fruit\\Vegetarian'}]  ...              0   None   \n",
       "2064  [{'e': 'text', 't': 'Fruit\\Vegetarian'}]  ...              0   None   \n",
       "2065  [{'e': 'text', 't': 'Fruit\\Vegetarian'}]  ...              0   None   \n",
       "\n",
       "      is_video is_gallery  media_metadata  gallery_data poll_data  \\\n",
       "2061     False        NaN             NaN           NaN       NaN   \n",
       "2062     False        NaN             NaN           NaN       NaN   \n",
       "2063     False        NaN             NaN           NaN       NaN   \n",
       "2064     False        NaN             NaN           NaN       NaN   \n",
       "2065     False        NaN             NaN           NaN       NaN   \n",
       "\n",
       "      author_cakeday crosspost_parent_list  crosspost_parent  \n",
       "2061             NaN                   NaN               NaN  \n",
       "2062             NaN                   NaN               NaN  \n",
       "2063             NaN                   NaN               NaN  \n",
       "2064             NaN                   NaN               NaN  \n",
       "2065             NaN                   NaN               NaN  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts = pd.DataFrame(all_data_for_all_flairs)\n",
    "df_posts = pd.json_normalize(df_posts['data'], max_level=0)\n",
    "\n",
    "df_posts['permalink'] = \"https://reddit.com\" + df_posts['permalink']\n",
    "df_posts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2066 entries, 0 to 2065\n",
      "Columns: 117 entries, approved_at_utc to crosspost_parent\n",
      "dtypes: bool(30), float64(5), int64(10), object(72)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_posts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Save dataframe as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_json('../data/posts.json', orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Saving Dataframe as HTML for webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts = pd.read_json('../data/posts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts_styled = df_posts.head().style.set_table_styles([\n",
    "    {'selector': 'thead', 'props': [('background-color', '#f2f2f2')]},\n",
    "    {'selector': 'th', 'props': [('border', '1px solid #dddddd')]},\n",
    "    {'selector': 'td', 'props': [('border', '1px solid #dddddd')]},\n",
    "])\n",
    "\n",
    "df_posts_styled.to_html('../docs/posts.html', render_links=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds105",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
