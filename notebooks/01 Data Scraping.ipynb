{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âœ…Step 1: Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ðŸŽ¯Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import requests as r\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from scrapy import Selector\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import spacy\n",
    "# import plotnine\n",
    "# import altair\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our own modules\n",
    "sys.path.append(\"../scripts/\")\n",
    "import chadtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ðŸŽ¯Authenticate with Reddit API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a function defined in our `utils.py` script, we can authenticate with the Reddit API using our own `credentials.json` file, and get a `dict` of headers to be used in all subsequent GET requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNzA2MzA2MjQyLjI2ODQyMSwiaWF0IjoxNzA2MjE5ODQyLjI2ODQyMSwianRpIjoidWttdHQ3ZHd2U0Y4VXVHZFo4RlEzd05yajZUZkxBIiwiY2lkIjoibWhUbV82eEVUNzVkOWhmWkJrS0ZYQSIsImxpZCI6InQyXzE2ZmE0MiIsImFpZCI6InQyXzE2ZmE0MiIsImxjYSI6MTQ5MDI0NzcyNzAxMSwic2NwIjoiZUp5S1Z0SlNpZ1VFQUFEX193TnpBU2MiLCJmbG8iOjl9.cmaqo5qFcyWHTVnv7tbF9AV-i0pnU272nP-PjMw2onByq6kByTNGbC9iDPk4cRZwuBqYxeVS3Y5Yn2kX0clC8G4oKMQN4ZIkCa65uW3Jf0V47_CtpUoT22urkux5PpwEHT-annWXFCOD7-pk5REmj3ldbSRQmEDswSHhFpkWpIEY5CwAfsLiOeMIfp3nOMM-l0TYwU4eB4KOt6E9WUwIV4tcn-lyGRGV5qFfH95bHJvzmwVPdc0A16HuY3L8V44eNMGhqkPs0cn3BMCw9inmP35KkVm6zz9Wx1w82UvCNeRz5IFDoDbPQ-w3jt1Va5K0Wz9Swzrd60-lVKrtmq2zFQ',\n",
       " 'User-Agent': 'LSE DS105A Recipe Scraping Project by zichengliu'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = chadtools.authenticate_and_get_headers()\n",
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ðŸŽ¯Sending our GET requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prepare GET request for all Flairs + Paginate through all search results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to loop through each flair using For Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `after` ID given by the reddit API to paginate through until the last post matching the search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2066"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = r.Session()\n",
    "BASE_ENDPOINT = \"https://oauth.reddit.com\"\n",
    "flair_names = ['Recipe', 'Dessert', 'Pasta', 'Poultry', 'Vegetarian', 'Drink', 'Beef', 'Pork', 'Seafood', 'Fruit\\Vegetarian']\n",
    "subreddit_name = 'recipes'\n",
    "\n",
    "\n",
    "all_data_for_all_flairs = []\n",
    "all_data_by_flair = {}\n",
    "\n",
    "\n",
    "for flair in flair_names:\n",
    "    flair_query = f'flair_name:\"{flair}\"'\n",
    "    specific_date_time = datetime(2020, 8, 31, 10, 59, 0)\n",
    "    timestamp = int(specific_date_time.timestamp())\n",
    "    params = {\n",
    "        'q': flair_query,\n",
    "        'limit': 100,\n",
    "        'restrict_sr': 1,\n",
    "        'sort': 'new',\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "    response = s.get(f\"{BASE_ENDPOINT}/r/{subreddit_name}/search\", params=params, headers=headers)\n",
    "    # Initialize an empty list to store the data from page for the current flair\n",
    "    all_data_by_flair[flair] = []\n",
    "    \n",
    "\n",
    "    # Process the data from the first page\n",
    "    data = response.json()\n",
    "    all_data_by_flair[flair].extend(data['data']['children'])\n",
    "\n",
    "    # Page 02 and beyond\n",
    "    while 'after' in data['data'] and data['data']['after'] is not None:\n",
    "        after_id = data['data']['after']\n",
    "        params[\"after\"] = after_id\n",
    "        response = s.get(f\"{BASE_ENDPOINT}/r/{subreddit_name}/search\", params=params, headers=headers)\n",
    "        # print(f\"Requesting Page {len(all_data_by_flair[flair]) // params['limit'] + 1}\")\n",
    "        data = response.json()\n",
    "\n",
    "        # Process the data from the current page\n",
    "        #all_data_by_flair.extend(data['data']['children'])\n",
    "        all_data_by_flair[flair].extend(data['data']['children'])\n",
    "    \n",
    "    all_data_for_all_flairs.extend(all_data_by_flair[flair])\n",
    "    \n",
    "len(all_data_for_all_flairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ðŸŽ¯Saving the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Save the data as a JSON file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/all_data_for_all_flairs.json\", \"w\") as f:\n",
    "    json.dump(all_data_for_all_flairs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load the JSON file as a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/all_data_for_all_flairs.json\", \"r\") as file:\n",
    "    posts = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create a dataframe of all posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>is_gallery</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>gallery_data</th>\n",
       "      <th>poll_data</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>author_cakeday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>None</td>\n",
       "      <td>recipes</td>\n",
       "      <td></td>\n",
       "      <td>t2_71qg7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Eggplant Chickpea Dip</td>\n",
       "      <td>[{'e': 'text', 't': 'Fruit\\Vegetarian'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>None</td>\n",
       "      <td>recipes</td>\n",
       "      <td></td>\n",
       "      <td>t2_3hz99hdf</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>End-Of-Summer Sesame Slaw</td>\n",
       "      <td>[{'e': 'text', 't': 'Fruit\\Vegetarian'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>None</td>\n",
       "      <td>recipes</td>\n",
       "      <td></td>\n",
       "      <td>t2_3ftl8yf0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Bhindi</td>\n",
       "      <td>[{'e': 'text', 't': 'Fruit\\Vegetarian'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>None</td>\n",
       "      <td>recipes</td>\n",
       "      <td></td>\n",
       "      <td>t2_3ftl8yf0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Restaurant Style Phool Gobhi Masala Recipe</td>\n",
       "      <td>[{'e': 'text', 't': 'Fruit\\Vegetarian'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>None</td>\n",
       "      <td>recipes</td>\n",
       "      <td></td>\n",
       "      <td>t2_71qg7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Celery and Soy Stuffed Butternut Squash</td>\n",
       "      <td>[{'e': 'text', 't': 'Fruit\\Vegetarian'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     approved_at_utc subreddit selftext author_fullname  saved  \\\n",
       "2061            None   recipes                 t2_71qg7  False   \n",
       "2062            None   recipes              t2_3hz99hdf  False   \n",
       "2063            None   recipes              t2_3ftl8yf0  False   \n",
       "2064            None   recipes              t2_3ftl8yf0  False   \n",
       "2065            None   recipes                 t2_71qg7  False   \n",
       "\n",
       "     mod_reason_title  gilded  clicked  \\\n",
       "2061             None       0    False   \n",
       "2062             None       0    False   \n",
       "2063             None       0    False   \n",
       "2064             None       0    False   \n",
       "2065             None       0    False   \n",
       "\n",
       "                                           title  \\\n",
       "2061                       Eggplant Chickpea Dip   \n",
       "2062                   End-Of-Summer Sesame Slaw   \n",
       "2063                                      Bhindi   \n",
       "2064  Restaurant Style Phool Gobhi Masala Recipe   \n",
       "2065     Celery and Soy Stuffed Butternut Squash   \n",
       "\n",
       "                           link_flair_richtext  ... num_crossposts  media  \\\n",
       "2061  [{'e': 'text', 't': 'Fruit\\Vegetarian'}]  ...              0   None   \n",
       "2062  [{'e': 'text', 't': 'Fruit\\Vegetarian'}]  ...              0   None   \n",
       "2063  [{'e': 'text', 't': 'Fruit\\Vegetarian'}]  ...              0   None   \n",
       "2064  [{'e': 'text', 't': 'Fruit\\Vegetarian'}]  ...              0   None   \n",
       "2065  [{'e': 'text', 't': 'Fruit\\Vegetarian'}]  ...              0   None   \n",
       "\n",
       "      is_video is_gallery  media_metadata  gallery_data poll_data  \\\n",
       "2061     False        NaN             NaN           NaN       NaN   \n",
       "2062     False        NaN             NaN           NaN       NaN   \n",
       "2063     False        NaN             NaN           NaN       NaN   \n",
       "2064     False        NaN             NaN           NaN       NaN   \n",
       "2065     False        NaN             NaN           NaN       NaN   \n",
       "\n",
       "      crosspost_parent_list crosspost_parent  author_cakeday  \n",
       "2061                    NaN              NaN             NaN  \n",
       "2062                    NaN              NaN             NaN  \n",
       "2063                    NaN              NaN             NaN  \n",
       "2064                    NaN              NaN             NaN  \n",
       "2065                    NaN              NaN             NaN  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts = pd.DataFrame(posts)\n",
    "df_posts = pd.json_normalize(df_posts['data'], max_level=0)\n",
    "\n",
    "# selected_cols = ['title', 'created_utc', 'ups', 'downs', 'upvote_ratio', 'score', 'num_comments', 'is_original_content', 'permalink', 'url']\n",
    "\n",
    "# filter out only the columns we want\n",
    "# df_posts = df_posts[selected_cols].copy()\n",
    "df_posts['permalink'] = \"https://reddit.com\" + df_posts['permalink']\n",
    "df_posts.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-English posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the data easier to analyse using NLP techniques, we will filter out posts that are not in English."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load the English language model into spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# filter the english posts by applying custom function\n",
    "filtered_df_posts = df_posts[df_posts['title'].apply(chadtools.is_english, model=nlp)]\n",
    "filtered_df_posts.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Save dataframe as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_json('../data/posts.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds105",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
